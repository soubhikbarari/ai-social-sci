# ai-social-sci (under construction)
*Repo of papers and notes on (broadly) the intersection of AI and social science.*

Ashwin, J., Chhabra, A., & Rao, V. (2023). Using large language models for qualitative analysis can introduce serious bias. arXiv preprint arXiv:2309.17147. 
- Publication: https://journals.sagepub.com/doi/10.1177/00491241251338246

Westwood, S. J., Grimmer, J., & Hall, A. B. (2025). Measuring Perceived Slant in Large Language Models Through User Evaluations. 
- Preprint: https://modelslant.com/paper.pdf

Moore, J., Grabb, D., Agnew, W., Klyman, K., Chancellor, S., Ong, D. C., & Haber, N. (2025). Expressing stigma and inappropriate responses prevents LLMs from safely replacing mental health providers. In Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency (FAccT '25). Association for Computing Machinery.
- Preprint: https://arxiv.org/abs/2504.18412
- Github: https://github.com/jlcmoore/llms-as-therapists

von der Heyde, L., Haensch, A. C., & Wenz, A. (2024). Vox populi, vox ai? using language models to estimate german public opinion. arXiv preprint arXiv:2407.08563.
- Preprint: https://arxiv.org/abs/2407.08563

https://arxiv.org/abs/2505.23836

https://arxiv.org/abs/2409.14202

https://arxiv.org/abs/2506.00856

https://arxiv.org/abs/2402.02636

https://arxiv.org/abs/2311.08605

https://www.nber.org/papers/w33777

https://arxiv.org/abs/2402.01656

https://www.turing.ac.uk/news/publications/mapping-potential-generative-ai-and-public-sector-work-using-time-use-data

https://psychometrics.ai/

https://www.pnas.org/doi/10.1073/pnas.2501660122
