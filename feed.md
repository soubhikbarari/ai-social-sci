Ashwin, J., Chhabra, A., & Rao, V. (2023). Using large language models for qualitative analysis can introduce serious bias. arXiv preprint arXiv:2309.17147. 
https://journals.sagepub.com/doi/10.1177/00491241251338246

Westwood, S. J., Grimmer, J., & Hall, A. B. (2025). Measuring Perceived Slant in Large Language Models Through User Evaluations. 
https://modelslant.com/paper.pdf

Moore, J., Grabb, D., Agnew, W., Klyman, K., Chancellor, S., Ong, D. C., & Haber, N. (2025). Expressing stigma and inappropriate responses prevents LLMs from safely replacing mental health providers. In Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency (FAccT '25). Association for Computing Machinery.
https://arxiv.org/abs/2504.18412

von der Heyde, L., Haensch, A. C., & Wenz, A. (2024). Vox populi, vox ai? using language models to estimate german public opinion. arXiv preprint arXiv:2407.08563.
- Preprint: https://arxiv.org/abs/2407.08563

United in Diversity? Contextual Biases in LLM-Based Predictions of the 2024 European Parliament Elections
https://arxiv.org/abs/2409.09045

AIn't Nothing But a Survey? Using Large Language Models for Coding German Open-Ended Survey Responses on Survey Motivation
https://arxiv.org/abs/2506.14634

Large Language Models Often Know When They Are Being Evaluated
https://arxiv.org/abs/2505.23836

Mining Causality: AI-Assisted Search for Instrumental Variables
https://arxiv.org/abs/2409.14202

Can AI Master Econometrics? Evidence from Econometrics AI Agent on Expert-Level Tasks
https://arxiv.org/abs/2506.00856

Can Large Language Models Learn Independent Causal Mechanisms?
https://arxiv.org/abs/2402.02636

Exploring the Jungle of Bias: Political Bias Attribution in Language Models via Dependency Analysis
https://arxiv.org/abs/2311.08605

Large Language Models, Small Labor Market Effects
https://www.nber.org/papers/w33777

Promises and pitfalls of artificial intelligence for legal applications
https://arxiv.org/abs/2402.01656

Mapping the Potential of Generative AI and Public Sector Work: Using time use data to identify opportunities for AI adoption in Great Britain's public sector
https://www.turing.ac.uk/news/publications/mapping-potential-generative-ai-and-public-sector-work-using-time-use-data

Psychometrics.ai: AI for Psychological Measurement
https://psychometrics.ai/

Take caution in using LLMs as human surrogates
https://www.pnas.org/doi/10.1073/pnas.2501660122

Opportunities and risks of LLMs in survey research
https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5001645

Predicting Empirical AI Research Outcomes with Language Models
https://arxiv.org/abs/2506.00794

Synthetic Replacements for Human Survey Data? The Perils of Large Language Models
https://www.cambridge.org/core/journals/political-analysis/article/synthetic-replacements-for-human-survey-data-the-perils-of-large-language-models/B92267DC26195C7F36E63EA04A47D2FE

Generative Agent Simulations of 1,000 People
https://arxiv.org/abs/2411.10109

LLMs generate structurally realistic social networks but overestimate political homophily
https://arxiv.org/abs/2408.16629

ChatBench: From Static Benchmarks to Human-AI Evaluation
https://arxiv.org/abs/2504.07114

Language Model Fine-Tuning on Scaled Survey Data for Predicting Distributions of Public Opinions
https://arxiv.org/abs/2502.16761

Bias in Large Language Models: Origin, Evaluation, and Mitigation
https://arxiv.org/abs/2411.10915

Bias and Fairness in Large Language Models: A Survey
https://arxiv.org/abs/2309.00770

Measurement in the Age of LLMs: An Application to Ideological Scaling
https://arxiv.org/abs/2312.09203

Large Language Models Reflect the Ideology of their Creators
https://arxiv.org/abs/2410.18417

Future of Work with AI Agents: Auditing Automation and Augmentation Potential across the U.S. Workforce
https://arxiv.org/pdf/2506.06576

Ferrara E (2024). The Butterfly Effect in artificial intelligence systems: Implications for AI bias and fairness. Machine Learning with Applications, Volume 15.
https://www.sciencedirect.com/science/article/pii/S266682702400001X

Potemkin Understanding in Large Language Models
https://arxiv.org/abs/2506.21521

AI-augmented government transformation: Organisational transformation and the sociotechnical implications of artificial intelligence in public administrations
https://www.sciencedirect.com/science/article/pii/S0740624X25000498

The Political Effects of the AI Revolution: Micro-level Evidence
https://osf.io/preprints/socarxiv/4xdn8_v1

Boelaert, J., Coavoux, S., Ollion, É., Petev, I., & Präg, P. (2025). Machine Bias. How Do Generative Language Models Answer Opinion Polls?. Sociological Methods & Research, 54(3), 1156-1196. https://doi.org/10.1177/00491241251330582 (Original work published 2025)

Machine Bias. How Do Generative Language Models Answer Opinion Polls?
https://journals.sagepub.com/doi/10.1177/00491241251330582

A foundation model to predict and capture human cognition
https://www.nature.com/articles/s41586-025-09215-4

Emergent analogical reasoning in large language models
https://www.nature.com/articles/s41562-023-01659-w

Large-scale AI language systems display an emergent ability to reason by analogy
https://www.nature.com/articles/s41562-023-01671-0

Large Language Models and Emergence: A Complex Systems Perspective
https://arxiv.org/pdf/2506.11135

Could AI Leapfrog the Web? Evidence from Teachers in Sierra Leone
https://arxiv.org/abs/2502.12397

Your Brain on ChatGPT: Accumulation of Cognitive Debt when Using an AI Assistant for Essay Writing Task
https://arxiv.org/abs/2506.08872

GenAI-Powered Inference
https://arxiv.org/pdf/2507.03897

Causal Representation Learning with Generative Artificial Intelligence: Application to Texts as Treatments
https://arxiv.org/pdf/2410.00903

The Impact of AI on Developer Productivity: Evidence from GitHub Copilot
https://arxiv.org/pdf/2302.06590

The Rise of AI Companions: How Human-Chatbot Relationships Influence Well-Being
https://arxiv.org/pdf/2506.12605

A Framework to Assess the Persuasion Risks Large Language Model Chatbots Pose to Democratic Societies
https://arxiv.org/pdf/2505.00036

Measuring the Impact of Early-2025 AI on Experienced Open-Source Developer Productivity
- https://metr.org/Early_2025_AI_Experienced_OS_Devs_Study.pdf
- https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/#:~:text=Core%20Result,developer%20beliefs%20and%20expert%20forecasts.

A National Synthetic Populations Dataset for the United States
https://www.nature.com/articles/s41597-025-04380-7

The Mixed Subjects Design: Treating Large Language Models as Potentially Informative Observations
https://journals.sagepub.com/doi/10.1177/00491241251326865

The Levers of Political Persuasion with Conversational AI
https://www.arxiv.org/abs/2507.13919

Dispelling Myths of AI and Efficiency
https://datasociety.net/wp-content/uploads/2025/03/Dispelling-Myths-of-AI-and-Efficiency-1.pdf

AI-Ready Federal Statistical Data: An Extension of Communicating Data Quality
https://www.fcsm.gov/assets/files/docs/FCSM.25.03_AI-Ready-Extension-Data-Quality.pdf

The Impact of Generative AI on Work Productivity
https://www.stlouisfed.org/on-the-economy/2025/feb/impact-generative-ai-work-productivity#:~:text=Together%2C%20the%20model%20and%20data,that%20they%20use%20generative%20AI.

Sorokovikova, A., Chizhov, P., Eremenko, I., & Yamshchikov, I. P. (2025). Surface Fairness, Deep Bias: A Comparative Study of Bias in Language Models.
https://arxiv.org/abs/2506.10491

PERSONA VECTORS: MONITORING AND CONTROLLING CHARACTER TRAITS IN LANGUAGE MODELS
https://arxiv.org/pdf/2507.21509
